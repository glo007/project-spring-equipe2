# project-datatrack-equipe2  
**TP DataOps â€” Suivi des performances scolaires des Ã©tudiants (Scrum Simulation)**  

---

# Projet DataTrack - Sprint 1 (DataOps)

---

## Contexte du projet

Lâ€™entreprise souhaite mieux comprendre les **facteurs influenÃ§ant la rÃ©ussite scolaire** des Ã©tudiants.  
Pour cela, elle veut mettre en place un **pipeline DataOps automatisÃ©** capable de :

- Extraire le dataset depuis **Kaggle** (*Students Performance Dataset*),  
- Nettoyer et transformer les donnÃ©es (scores, genre, origine ethnique, niveau parentalâ€¦),  
- Charger ces donnÃ©es dans une base centralisÃ©e,  
- Et les visualiser dans un **tableau de bord analytique**.  

 **Objectif final :** identifier des *patterns et insights* liÃ©s Ã  la rÃ©ussite scolaire (par exemple : influence du niveau parental sur les scores).

---

##  Organisation Scrum de lâ€™Ã©quipe

| RÃ´le | Membre | ResponsabilitÃ©s principales |
|------|---------|-----------------------------|
| **Product Owner (PO)** | **Arcy** | DÃ©finit les prioritÃ©s, rÃ©dige les User Stories, valide les livrables. |
| **Scrum Master (SM)** | **Ann-Jireh** | Facilite la mÃ©thode Scrum, anime les rÃ©unions, supervise le sprint (faible charge). |
| **DataOps Engineer / DÃ©veloppeur principal** | **Gloire** | Met en place le pipeline complet : extraction, transformation, chargement, visualisation. |

 *Ann-Jireh* a une mission lÃ©gÃ¨re de coordination, sans tÃ¢ches techniques lourdes.  
La majoritÃ© du travail technique est assurÃ©e par *Gloire*, sous la supervision dâ€™*Arcy* (PO).

---

##  Objectifs du Sprint 1

- Simuler un sprint Scrum complet (1 semaine).  
- Identifier et dÃ©crire les User Stories principales.  
- DÃ©tailler les tÃ¢ches techniques et leur complexitÃ©.  
- Planifier le sprint et rÃ©partir les responsabilitÃ©s.  
- Documenter le travail collaboratif (README + Scrum doc).  

---

##  Organisation GitHub Project

**Nom du projet :** `Sprint 1 - DataOps`  
**Type :** Kanban Board  

**Colonnes :**
- To do  
- In progress  
- In review  
- Done  

Chaque **issue** = une **User Story (US)**  
Chaque US contient :  
â†’ DÃ©tail de la fonctionnalitÃ©  
â†’ CritÃ¨res dâ€™acceptation  
â†’ TÃ¢ches techniques  

---

##  Product Backlog â€” User Stories (US)

| ID | User Story | Description | Responsable | Estimation (SP) |
|----|-------------|--------------|--------------|-----------------|
| **US1** | Extraction des donnÃ©es depuis Kaggle | En tant que DataOps Engineer, je veux automatiser le tÃ©lÃ©chargement du dataset depuis Kaggle pour alimenter le pipeline. | **Gloire** | 5 |
| **US2** | Nettoyage et prÃ©paration du dataset | En tant que DataOps Engineer, je veux nettoyer et transformer les donnÃ©es pour quâ€™elles soient prÃªtes Ã  lâ€™analyse. | **Gloire** | 3 |
| **US3** | Stockage structurÃ© des donnÃ©es | En tant que DataOps Engineer, je veux charger les donnÃ©es nettoyÃ©es dans une base PostgreSQL pour les rendre accessibles. | **Gloire** | 3 |
| **US4** | Tableau de bord analytique | En tant quâ€™analyste, je veux visualiser les scores par genre, origine, et niveau parental dans un dashboard Streamlit. | **Gloire** | 8 |
| **US5** | Supervision du pipeline | En tant que Scrum Master, je veux un systÃ¨me de logs et suivi du pipeline pour dÃ©tecter les erreurs. | **Ann-Jireh** | 2 |
| **US6** | Documentation et suivi du sprint | En tant que Product Owner, je veux rÃ©diger la documentation du projet et suivre le backlog. | **Arcy** | 3 |

---

##  DÃ©tail des tÃ¢ches techniques (Sprint Backlog)

| User Story | TÃ¢ches | Responsable | Estimation (SP) | Livrable attendu |
|-------------|--------|--------------|------------------|------------------|
| **US1** | TÃ©lÃ©charger le dataset Kaggle (API ou manuel), sauvegarder localement. | Gloire | 3 | Dataset brut (`/data/raw/students_performance.csv`) |
| **US1** | DÃ©finir le dossier de travail et les logs de tÃ©lÃ©chargement. | Gloire | 2 | Script `extract_kaggle.py` |
| **US2** | Nettoyer les colonnes (valeurs manquantes, doublons). | Gloire | 3 | Script `clean_data.py` |
| **US3** | CrÃ©er la base PostgreSQL et les tables `students_raw` / `students_clean`. | Gloire | 3 | Script `load_postgres.py` |
| **US4** | CrÃ©er le dashboard Streamlit : histogrammes et moyennes par catÃ©gorie. | Gloire | 8 | `dashboard.py` (Streamlit) |
| **US5** | Ajouter un fichier de logs (suivi des Ã©tapes et erreurs). | Ann-Jireh | 2 | `logging_system.py` |
| **US6** | RÃ©diger le `README.md`, la doc Scrum et le backlog du sprint. | Arcy | 3 | `docs/Documentation_Scrum.md` |

---

##  Estimation des Story Points (suite de Fibonacci)

| ComplexitÃ© | Valeur | Exemple |
|-------------|--------|----------|
| TrÃ¨s simple | 1 | Ajustement ou test mineur |
| Simple | 2 | Script court ou tÃ¢che lÃ©gÃ¨re |
| Moyenne | 3 | Script standard (nettoyage, chargement) |
| Complexe | 5 | Pipeline complet ou automatisation |
| TrÃ¨s complexe | 8 | Dashboard ou intÃ©gration complÃ¨te |

---

##  Planification du Sprint 1

| Sprint | DurÃ©e | Objectif principal |
|--------|--------|--------------------|
| **Sprint 1** | 1 semaine | Concevoir le pipeline complet du dataset Kaggle et livrer un tableau de bord fonctionnel. |

### ðŸŽ¯ Livrables attendus :
- Dataset tÃ©lÃ©chargÃ© depuis Kaggle  
- DonnÃ©es nettoyÃ©es et stockÃ©es dans PostgreSQL  
- Dashboard Streamlit avec indicateurs clÃ©s  
- Documentation complÃ¨te du sprint  

---

##  Ã‰vÃ©nements Scrum simulÃ©s

| Ã‰vÃ©nement | Objectif | DurÃ©e indicative |
|------------|-----------|------------------|
| **Sprint Planning** | Planifier les US Ã  rÃ©aliser dans le sprint | 1h |
| **Daily Scrum** | Faire le point sur les avancements (simulÃ©) | 15 min |
| **Sprint Review** | PrÃ©senter les livrables au Product Owner | 30 min |
| **Sprint Retrospective** | Identifier les amÃ©liorations possibles | 30 min |

---

##  Bilan du Sprint 1

| Question | RÃ©ponse |
|-----------|----------|
|  Ce qui a bien fonctionnÃ© | Bonne coordination et rÃ©partition claire du travail. |
|  Ce qui aurait pu mieux se passer | Le tÃ©lÃ©chargement du dataset a pris plus de temps que prÃ©vu. |
|  AmÃ©liorations pour le prochain sprint | Automatiser totalement lâ€™extraction Kaggle via API et ajouter plus de visualisations. |

---

## Tableau Sprint Backlog â€” SynthÃ¨se

| User Story | Responsable | Estimation (SP) | Livrable attendu | Statut |
|-------------|--------------|------------------|------------------|--------|
| **US1 â€“ Extraction Kaggle** | Gloire | 5 | Script `extract_kaggle.py` | ðŸŸ¡ In progress |
| **US2 â€“ Nettoyage des donnÃ©es** | Gloire | 3 | Script `clean_data.py` | ðŸ”µ To do |
| **US3 â€“ Chargement PostgreSQL** | Gloire | 3 | Script `load_postgres.py` | ðŸ”µ To do |
| **US4 â€“ Dashboard Streamlit** | Gloire | 8 | `dashboard.py` | ðŸ”µ To do |
| **US5 â€“ Supervision / Logs** | Ann-Jireh | 2 | `logging_system.py` | ðŸŸ¢ Done |
| **US6 â€“ Documentation / Backlog** | Arcy | 3 | `README.md`, `Documentation_Scrum.md` | ðŸŸ¢ Done |

---

##  Documentation Scrum intÃ©grÃ©e

###  Principes clÃ©s
Scrum repose sur trois piliers : **transparence**, **inspection**, **adaptation**.  
Chaque sprint vise Ã  produire un livrable fonctionnel, Ã  inspecter le rÃ©sultat et Ã  sâ€™amÃ©liorer.

---

###  RÃ´les Scrum
- **Product Owner (Arcy)** : fixe les prioritÃ©s et valide les livrables.  
- **Scrum Master (Ann-Jireh)** : anime les cÃ©rÃ©monies et veille Ã  la mÃ©thode (faible charge).  
- **DÃ©veloppeur DataOps (Gloire)** : rÃ©alise la majoritÃ© des tÃ¢ches techniques.

---

###  Cycle du Sprint
---

###  Objectif final
Ã€ la fin du Sprint 1, lâ€™Ã©quipe doit :
- Avoir simulÃ© un **pipeline DataOps complet**,  
- LivrÃ© une documentation claire et structurÃ©e,  
- Et dÃ©montrÃ© sa capacitÃ© Ã  travailler en mode **Scrum**.

---

>  *â€œInspecter, adapter et livrer de la valeur â€” mÃªme dans la donnÃ©e.â€*  
> â€” Ã‰quipe 2 : **Arcy**, **Ann-Jireh**, **Gloire**
